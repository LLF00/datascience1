{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ‚Äúmidterm_partone.csv‚Äù file that contains the stock-return information of small retailers    \n",
    "(the same as the one we used in Session 5). Suppose that an industry expert (e.g., David Berman)   \n",
    "claims that there is a bias in moment conditions of instrumental variables such that   \n",
    "ùëç!(ùëå ‚àí ùëãùêµ) = ùõø *   \n",
    "111\n",
    ",, where ùõø has a non-zero value.\n",
    "1. Update the GMM model that we discussed in class by incorporating the ùõø term to the\n",
    "instrumental-variable moment expressions.\n",
    "2. By analyzing the GMM summary table and test statistics of coefficients, determine if the\n",
    "industry expert‚Äôs claim is statistically justified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS \n",
    "# There is a package named IV2SLS in Python. Do not use this package! The exogenous explanatory variables must\n",
    "# be entered as instruments. So it gives wrong answers\n",
    "from statsmodels.sandbox.regression.gmm import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Constant</th>\n",
       "      <th>Stock Change</th>\n",
       "      <th>Inventory Turnover</th>\n",
       "      <th>Operating Profit</th>\n",
       "      <th>Interaction Effect</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Debt Asset Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.870332</td>\n",
       "      <td>1.795946</td>\n",
       "      <td>0.115846</td>\n",
       "      <td>0.208053</td>\n",
       "      <td>1.672527</td>\n",
       "      <td>0.255171</td>\n",
       "      <td>0.473317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.047347</td>\n",
       "      <td>1.395501</td>\n",
       "      <td>0.436967</td>\n",
       "      <td>0.609788</td>\n",
       "      <td>1.637261</td>\n",
       "      <td>0.221763</td>\n",
       "      <td>0.489967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>1.664563</td>\n",
       "      <td>0.541016</td>\n",
       "      <td>0.900555</td>\n",
       "      <td>1.640619</td>\n",
       "      <td>0.189141</td>\n",
       "      <td>0.374269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.901200</td>\n",
       "      <td>1.605738</td>\n",
       "      <td>0.539399</td>\n",
       "      <td>0.866133</td>\n",
       "      <td>1.436221</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.224399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.176353</td>\n",
       "      <td>1.591451</td>\n",
       "      <td>0.539938</td>\n",
       "      <td>0.859285</td>\n",
       "      <td>1.433140</td>\n",
       "      <td>0.183095</td>\n",
       "      <td>0.213446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Constant  Stock Change  Inventory Turnover  Operating Profit  \\\n",
       "0         1      0.870332            1.795946          0.115846   \n",
       "1         1     -0.047347            1.395501          0.436967   \n",
       "2         1      0.001176            1.664563          0.541016   \n",
       "3         1     -0.901200            1.605738          0.539399   \n",
       "4         1     -0.176353            1.591451          0.539938   \n",
       "\n",
       "   Interaction Effect  Current Ratio  Quick Ratio  Debt Asset Ratio  \n",
       "0            0.208053       1.672527     0.255171          0.473317  \n",
       "1            0.609788       1.637261     0.221763          0.489967  \n",
       "2            0.900555       1.640619     0.189141          0.374269  \n",
       "3            0.866133       1.436221     0.131944          0.224399  \n",
       "4            0.859285       1.433140     0.183095          0.213446  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(r\"D:\\1.5110 Predictive Modeling\\midterm_partone.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_iv = sm.OLS(df1[\"Inventory Turnover\"],df1[[\"Constant\",\"Current Ratio\",\"Quick Ratio\",\\\n",
    "                                                                 \"Debt Asset Ratio\"]]).fit()\n",
    "endog_predict = model_iv.predict(df1[[\"Constant\",\"Current Ratio\",\"Quick Ratio\",\"Debt Asset Ratio\"]])\n",
    "df1[\"Endogenous Param\"] = endog_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Stock Change</td>   <th>  R-squared:         </th> <td>   0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 08 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>1.27e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:49:54</td>     <th>  Log-Likelihood:    </th> <td> -1186.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1696</td>      <th>  AIC:               </th> <td>   2381.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1692</td>      <th>  BIC:               </th> <td>   2403.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Constant</th>           <td>   -0.0176</td> <td>    0.020</td> <td>   -0.896</td> <td> 0.370</td> <td>   -0.056</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Endogenous Param</th>   <td>    0.0011</td> <td>    0.001</td> <td>    1.827</td> <td> 0.068</td> <td>-7.76e-05</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Operating Profit</th>   <td>   -0.1201</td> <td>    0.028</td> <td>   -4.319</td> <td> 0.000</td> <td>   -0.175</td> <td>   -0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Interaction Effect</th> <td>    0.0014</td> <td>    0.000</td> <td>    3.621</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>368.832</td> <th>  Durbin-Watson:     </th> <td>   2.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3433.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.742</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.811</td>  <th>  Cond. No.          </th> <td>    109.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}     &   Stock Change   & \\textbf{  R-squared:         } &     0.015   \\\\\n",
       "\\textbf{Model:}             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.013   \\\\\n",
       "\\textbf{Method:}            &  Least Squares   & \\textbf{  F-statistic:       } &     8.530   \\\\\n",
       "\\textbf{Date:}              & Wed, 08 Nov 2023 & \\textbf{  Prob (F-statistic):} &  1.27e-05   \\\\\n",
       "\\textbf{Time:}              &     20:49:54     & \\textbf{  Log-Likelihood:    } &   -1186.5   \\\\\n",
       "\\textbf{No. Observations:}  &        1696      & \\textbf{  AIC:               } &     2381.   \\\\\n",
       "\\textbf{Df Residuals:}      &        1692      & \\textbf{  BIC:               } &     2403.   \\\\\n",
       "\\textbf{Df Model:}          &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Constant}           &      -0.0176  &        0.020     &    -0.896  &         0.370        &       -0.056    &        0.021     \\\\\n",
       "\\textbf{Endogenous Param}   &       0.0011  &        0.001     &     1.827  &         0.068        &    -7.76e-05    &        0.002     \\\\\n",
       "\\textbf{Operating Profit}   &      -0.1201  &        0.028     &    -4.319  &         0.000        &       -0.175    &       -0.066     \\\\\n",
       "\\textbf{Interaction Effect} &       0.0014  &        0.000     &     3.621  &         0.000        &        0.001    &        0.002     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 368.832 & \\textbf{  Durbin-Watson:     } &    2.243  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3433.920  \\\\\n",
       "\\textbf{Skew:}          &   0.742 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   9.811 & \\textbf{  Cond. No.          } &     109.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           Stock Change   R-squared:                       0.015\n",
       "Model:                            OLS   Adj. R-squared:                  0.013\n",
       "Method:                 Least Squares   F-statistic:                     8.530\n",
       "Date:                Wed, 08 Nov 2023   Prob (F-statistic):           1.27e-05\n",
       "Time:                        20:49:54   Log-Likelihood:                -1186.5\n",
       "No. Observations:                1696   AIC:                             2381.\n",
       "Df Residuals:                    1692   BIC:                             2403.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Constant              -0.0176      0.020     -0.896      0.370      -0.056       0.021\n",
       "Endogenous Param       0.0011      0.001      1.827      0.068   -7.76e-05       0.002\n",
       "Operating Profit      -0.1201      0.028     -4.319      0.000      -0.175      -0.066\n",
       "Interaction Effect     0.0014      0.000      3.621      0.000       0.001       0.002\n",
       "==============================================================================\n",
       "Omnibus:                      368.832   Durbin-Watson:                   2.243\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3433.920\n",
       "Skew:                           0.742   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.811   Cond. No.                         109.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2sls = sm.OLS(df1[\"Stock Change\"], df1[[\"Constant\",\"Endogenous Param\",\\\n",
    "                                                              \"Operating Profit\",\"Interaction Effect\",\\\n",
    "                                                             ]]).fit()\n",
    "model_2sls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000046\n",
      "         Iterations: 8\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000373\n",
      "         Iterations: 7\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000372\n",
      "         Iterations: 5\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000372\n",
      "         Iterations: 5\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000372\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>gmm Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  Hansen J:          </th> <td>  0.6317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>gmm</td>       <th>  Prob (Hansen J):   </th>  <td> 0.729</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>GMM</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 08 Nov 2023</td> <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:49:54</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1696</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 0</th> <td>   -0.0200</td> <td>    0.021</td> <td>   -0.964</td> <td> 0.335</td> <td>   -0.061</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 1</th> <td>    0.0011</td> <td>    0.001</td> <td>    1.843</td> <td> 0.065</td> <td>-6.89e-05</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 2</th> <td>   -0.1071</td> <td>    0.032</td> <td>   -3.370</td> <td> 0.001</td> <td>   -0.169</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p 3</th> <td>    0.0011</td> <td>    0.000</td> <td>    2.760</td> <td> 0.006</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  Hansen J:          } &    0.6317   \\\\\n",
       "\\textbf{Model:}            &       gmm        & \\textbf{  Prob (Hansen J):   } &    0.729    \\\\\n",
       "\\textbf{Method:}           &       GMM        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Date:}             & Wed, 08 Nov 2023 & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}             &     20:49:54     & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Observations:} &        1696      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "             & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{p 0} &      -0.0200  &        0.021     &    -0.964  &         0.335        &       -0.061    &        0.021     \\\\\n",
       "\\textbf{p 1} &       0.0011  &        0.001     &     1.843  &         0.065        &    -6.89e-05    &        0.002     \\\\\n",
       "\\textbf{p 2} &      -0.1071  &        0.032     &    -3.370  &         0.001        &       -0.169    &       -0.045     \\\\\n",
       "\\textbf{p 3} &       0.0011  &        0.000     &     2.760  &         0.006        &        0.000    &        0.002     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{gmm Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 gmm Results                                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   Hansen J:                       0.6317\n",
       "Model:                            gmm   Prob (Hansen J):                 0.729\n",
       "Method:                           GMM                                         \n",
       "Date:                Wed, 08 Nov 2023                                         \n",
       "Time:                        20:49:54                                         \n",
       "No. Observations:                1696                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "p 0           -0.0200      0.021     -0.964      0.335      -0.061       0.021\n",
       "p 1            0.0011      0.001      1.843      0.065   -6.89e-05       0.002\n",
       "p 2           -0.1071      0.032     -3.370      0.001      -0.169      -0.045\n",
       "p 3            0.0011      0.000      2.760      0.006       0.000       0.002\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vals  = np.array(df1[\"Stock Change\"])\n",
    "x_vals  = np.array(df1[[\"Inventory Turnover\",\"Operating Profit\",\"Interaction Effect\"]])\n",
    "iv_vals = np.array(df1[[\"Current Ratio\",\"Quick Ratio\",\"Debt Asset Ratio\"]])\n",
    "\n",
    "class gmm(GMM):\n",
    "    def momcond(self, params):\n",
    "        p0, p1, p2, p3 = params\n",
    "        endog = self.endog\n",
    "        exog = self.exog\n",
    "        inst = self.instrument   \n",
    "\n",
    "        error0 = endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]\n",
    "        error1 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * exog[:,1]\n",
    "        error2 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * exog[:,2]\n",
    "        error3 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * inst[:,0] \n",
    "        error4 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * inst[:,1] \n",
    "        error5 = (endog - p0 - p1 * exog[:,0] - p2 * exog[:,1] - p3 * exog[:,2]) * inst[:,2] \n",
    "\n",
    "        g = np.column_stack((error0, error1, error2, error3, error4, error5))\n",
    "        return g\n",
    "\n",
    "\n",
    "beta0 = np.array([0.1, 0.1, 0.1, 0.1])\n",
    "res = gmm(endog = y_vals, exog = x_vals, instrument = iv_vals, k_moms=6, k_params=4).fit(beta0)\n",
    "\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df2 = pd.read_csv(r\"D:\\1.5110 Predictive Modeling\\midterm_parttwo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Years of Education after High School</th>\n",
       "      <th>Requested Credit Amount</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Monthly Income</th>\n",
       "      <th>Monthly Expense</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Credit Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Married</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Single</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Single</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Married</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>No dependent</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Very low</td>\n",
       "      <td>Single</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Years of Education after High School Requested Credit Amount  \\\n",
       "0                                     1                     Low   \n",
       "1                                     2                     Low   \n",
       "2                                     1                     Low   \n",
       "3                                     3                     Low   \n",
       "4                                     3                     Low   \n",
       "\n",
       "  Number of Dependents Monthly Income Monthly Expense Marital Status  \\\n",
       "0         No dependent       Very low        Very low        Married   \n",
       "1         No dependent       Very low        Very low         Single   \n",
       "2         No dependent       Very low        Very low         Single   \n",
       "3         No dependent       Very low        Very low        Married   \n",
       "4         No dependent       Very low        Very low         Single   \n",
       "\n",
       "  Credit Rating  \n",
       "0      Positive  \n",
       "1      Positive  \n",
       "2      Positive  \n",
       "3      Positive  \n",
       "4      Negative  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets (50% each)\n",
    "train_data, test_data = train_test_split(df2, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "features = [\"Requested Credit Amount\", \"Marital Status\", \"Number of Dependents\", \n",
    "            \"Years of Education after High School\", \"Monthly Income\", \"Monthly Expense\"]\n",
    "target = \"Credit Rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using one-hot encoding\n",
    "train_data = pd.get_dummies(train_data, columns=features, drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(train_data.drop(columns=[target]), train_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict credit ratings on the test set\n",
    "predictions = model.predict(test_data.drop(columns=[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix, recall, precision, and F1 score\n",
    "conf_matrix = confusion_matrix(test_data[target], predictions)\n",
    "precision = precision_score(test_data[target], predictions, pos_label='Positive')\n",
    "recall = recall_score(test_data[target], predictions, pos_label='Positive')\n",
    "f1 = f1_score(test_data[target], predictions, pos_label='Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   0  577]\n",
      " [   0 3464]]\n",
      "Precision: 0.8572135609997525\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9231179213857428\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the threshold for the top 15% of predictions\n",
    "threshold = sorted(model.predict_proba(test_data.drop(columns=[target]))[:, 1], reverse=True)[int(len(test_data) * 0.15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the predictions based on the new threshold\n",
    "new_predictions = [1 if p >= threshold else 0 for p in model.predict_proba(test_data.drop(columns=[target]))[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=['Negative' 'Positive'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:113\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     unique_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munion1d(y_true, y_pred)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[39m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39m# strings. So we raise a meaningful error\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munion1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\arraysetops.py:932\u001b[0m, in \u001b[0;36munion1d\u001b[1;34m(ar1, ar2)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39mFind the union of two arrays.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39marray([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m \u001b[39mreturn\u001b[39;00m unique(np\u001b[39m.\u001b[39;49mconcatenate((ar1, ar2), axis\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mLLF00\\datascience1\\5140 modelling\\MBAN_midterm.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell://github/LLF00/datascience1/5140%20modelling/MBAN_midterm.ipynb#X31sdnNjb2RlLXZmcw%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calculate updated confusion matrix, recall, precision, and F1 score\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell://github/LLF00/datascience1/5140%20modelling/MBAN_midterm.ipynb#X31sdnNjb2RlLXZmcw%3D%3D?line=1'>2</a>\u001b[0m new_conf_matrix \u001b[39m=\u001b[39m confusion_matrix(test_data[target], new_predictions, labels\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mNegative\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPositive\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell://github/LLF00/datascience1/5140%20modelling/MBAN_midterm.ipynb#X31sdnNjb2RlLXZmcw%3D%3D?line=2'>3</a>\u001b[0m new_precision \u001b[39m=\u001b[39m precision_score(test_data[target], new_predictions, labels\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mNegative\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m\"\u001b[39m], pos_label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell://github/LLF00/datascience1/5140%20modelling/MBAN_midterm.ipynb#X31sdnNjb2RlLXZmcw%3D%3D?line=3'>4</a>\u001b[0m new_recall \u001b[39m=\u001b[39m recall_score(test_data[target], new_predictions, labels\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mNegative\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m\"\u001b[39m], pos_label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPositive\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[0;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:119\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    113\u001b[0m     unique_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munion1d(y_true, y_pred)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    115\u001b[0m     \u001b[39m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[39m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[39m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    120\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot y_true=\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_true)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred=\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_pred)\u001b[39m}\u001b[39;00m\u001b[39m. Make sure that the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpredictions provided by the classifier coincides with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe true labels.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unique_values) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    127\u001b[0m     y_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=['Negative' 'Positive'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels."
     ]
    }
   ],
   "source": [
    "# Calculate updated confusion matrix, recall, precision, and F1 score\n",
    "new_conf_matrix = confusion_matrix(test_data[target], new_predictions, labels=[\"Negative\", \"Positive\"])\n",
    "new_precision = precision_score(test_data[target], new_predictions, labels=[\"Negative\", \"Positive\"], pos_label=\"Positive\")\n",
    "new_recall = recall_score(test_data[target], new_predictions, labels=[\"Negative\", \"Positive\"], pos_label=\"Positive\")\n",
    "new_f1 = f1_score(test_data[target], new_predictions, labels=[\"Negative\", \"Positive\"], pos_label=\"Positive\")\n",
    "\n",
    "print(\"\\nUpdated Confusion Matrix:\")\n",
    "print(new_conf_matrix)\n",
    "print(\"Updated Precision:\", new_precision)\n",
    "print(\"Updated Recall:\", new_recall)\n",
    "print(\"Updated F1 Score:\", new_f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
